{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
       "0         0       3    0    1     0         0      1        0          3\n",
       "1         1       1    1    2     3         1      3        0          2\n",
       "2         1       3    1    1     1         0      2        1          3\n",
       "3         1       1    1    2     3         0      3        0          2\n",
       "4         0       3    0    2     1         0      1        1          6\n",
       "5         0       3    0    1     1         2      1        1          3\n",
       "6         0       1    0    3     3         0      1        1          3\n",
       "7         0       3    0    0     2         0      4        0          0\n",
       "8         1       3    1    1     1         0      3        0          3\n",
       "9         1       2    1    0     2         1      3        0          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']\n",
    "\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
    "\n",
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
       "0          892       3    0    2     0         2      1        1          6\n",
       "1          893       3    1    2     0         0      3        0          6\n",
       "2          894       2    0    3     1         2      1        1          6\n",
       "3          895       3    0    1     1         0      1        1          3\n",
       "4          896       3    1    1     1         0      3        0          3\n",
       "5          897       3    0    0     1         0      1        1          0\n",
       "6          898       3    1    1     0         2      2        1          3\n",
       "7          899       2    0    1     2         0      1        0          2\n",
       "8          900       3    1    1     0         1      3        1          3\n",
       "9          901       3    0    1     2         0      1        0          3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 / 891\n",
      "680 / 891\n",
      "690 / 891\n",
      "683 / 891\n",
      "704 / 891\n",
      "719 / 891\n",
      "698 / 891\n",
      "709 / 891\n",
      "707 / 891\n",
      "718 / 891\n",
      "716 / 891\n",
      "725 / 891\n",
      "722 / 891\n",
      "731 / 891\n",
      "708 / 891\n",
      "693 / 891\n",
      "732 / 891\n",
      "722 / 891\n",
      "729 / 891\n",
      "718 / 891\n",
      "711 / 891\n",
      "720 / 891\n",
      "726 / 891\n",
      "730 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n"
     ]
    }
   ],
   "source": [
    "training_data = train_df.values\n",
    "training_data = list(zip(training_data[:,1:], training_data[:,:1].reshape(-1, 1)))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))\n",
    "\n",
    "def vectorize(j):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        self.size = len(sizes)\n",
    "        self.layers = sizes\n",
    "        self.bias = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weight = [np.random.randn(x, y)\n",
    "                        for x, y in zip(sizes[1:], sizes[:-1])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        a = a.reshape(-1,1)\n",
    "        for b, w in zip(self.bias, self.weight):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            rnd.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size]\n",
    "                            for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                mini_batch = list(zip(*mini_batch))\n",
    "                mini_batch_x = np.column_stack(mini_batch[0])\n",
    "                mini_batch_y = np.column_stack(mini_batch[1])\n",
    "                self.update_mini_batch((mini_batch_x, mini_batch_y), eta)\n",
    "            print(str(self.evaluate(test_data))+\" / \"+str(len(test_data)))\n",
    "\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        mini_batch_x = mini_batch[0]\n",
    "        mini_batch_y = mini_batch[1]\n",
    "\n",
    "        gradient_w, gradient_b = self.backprop(mini_batch_x, mini_batch_y)\n",
    "        self.weight = [w-eta*nw\n",
    "                        for w, nw in zip(self.weight, gradient_w)]\n",
    "        self.bias = [b-eta*nb\n",
    "                        for b, nb in zip(self.bias, gradient_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        gradient_w = [np.zeros(w.shape) for w in self.weight]\n",
    "        gradient_b = [np.zeros(b.shape) for b in self.bias]\n",
    "        batch_size = len(x[0])\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for w, b in zip(self.weight, self.bias):\n",
    "            z = np.dot(w, x) + b\n",
    "            zs.append(z)\n",
    "            x = sigmoid(z)\n",
    "            activations.append(x)\n",
    "\n",
    "        deltaL = self.cost_derivative(x, y) * sigmoid_prime(zs[-1])\n",
    "        gradient_b[-1] = np.sum(deltaL, axis=1, keepdims=True) * 1.0 / batch_size\n",
    "        tmp_gradient_w = np.dot(deltaL, activations[-2].transpose())\n",
    "        gradient_w[-1] = tmp_gradient_w * 1.0 / batch_size\n",
    "\n",
    "        for l in range(2, self.size):\n",
    "            deltaL = np.dot(self.weight[-l+1].transpose(), deltaL) * sigmoid_prime(zs[-l])\n",
    "            gradient_b[-l] = np.sum(deltaL, axis=1, keepdims=True) * 1.0 / batch_size\n",
    "            tmp_gradient_w = np.dot(deltaL, activations[-l-1].transpose())\n",
    "            gradient_w[-l] =  tmp_gradient_w * 1.0 / batch_size\n",
    "\n",
    "        return (gradient_w, gradient_b)\n",
    "\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        result = [(int(self.feedforward(x)>=0.5), y)\n",
    "                    for x, y in test_data]\n",
    "        return sum([int(x==y) for x, y in result])\n",
    "        \n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return (output_activations - y)\n",
    "\n",
    "net = Network([8, 300, 1])\n",
    "net.SGD(training_data, 300, 10, 3.0, test_data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n",
      "549 / 891\n"
     ]
    }
   ],
   "source": [
    "training_data = train_df.values\n",
    "training_data = list(zip(training_data[:,1:], training_data[:,:1].reshape(-1, 1)))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))\n",
    "\n",
    "def vectorize(j):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "class QuadraticCost(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def fn(a, y):\n",
    "        return 0.5*np.linalg.norm(a-y)**2\n",
    "    \n",
    "    @staticmethod\n",
    "    def delta(z, a, y):\n",
    "        return (a-y) * sigmoid_prime(z)\n",
    "\n",
    "class CrossEntropyCost(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def fn(a, y):\n",
    "        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def delta(z, a, y):\n",
    "        return (a-y)\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes, cost=CrossEntropyCost):\n",
    "        self.size = len(sizes)\n",
    "        self.layers = sizes\n",
    "        self.default_weight_initializer()\n",
    "        self.cost=cost\n",
    "        \n",
    "    def default_weight_initializer(self):\n",
    "        self.bias = [np.random.randn(y, 1) for y in self.layers[1:]]\n",
    "        self.weight = [np.random.randn(y, x)/np.sqrt(x)\n",
    "                       for x, y in zip(self.layers[:-1], self.layers[1:])]\n",
    "\n",
    "    def large_weight_initializer(self):\n",
    "        self.bias = [np.random.randn(y, 1) for y in self.layers[1:]]\n",
    "        self.weight = [np.random.randn(y, x)\n",
    "                       for x, y in zip(self.layers[:-1], self.layers[1:])]\n",
    "        \n",
    "    def feedforward(self, a):\n",
    "        a = a.reshape(-1, 1)\n",
    "        for b, w in zip(self.bias, self.weight):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            lmbda = 0.0, test_data=None):\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            rnd.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size]\n",
    "                            for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                mini_batch = list(zip(*mini_batch))\n",
    "                mini_batch_x = np.column_stack(mini_batch[0])\n",
    "                mini_batch_y = np.column_stack(mini_batch[1])\n",
    "                self.update_mini_batch((mini_batch_x, mini_batch_y), eta, lmbda, n)\n",
    "            print(str(self.evaluate(test_data))+\" / \"+str(len(test_data)))\n",
    "\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, lmbda, n):\n",
    "        mini_batch_x = mini_batch[0]\n",
    "        mini_batch_y = mini_batch[1]\n",
    "       \n",
    "        gradient_w, gradient_b = self.backprop(mini_batch_x, mini_batch_y)\n",
    "        self.weight = [(1-eta*(lmbda/n))*w-eta*nw\n",
    "                        for w, nw in zip(self.weight, gradient_w)]\n",
    "        self.bias = [b-eta*nb\n",
    "                        for b, nb in zip(self.bias, gradient_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        gradient_w = [np.zeros(w.shape) for w in self.weight]\n",
    "        gradient_b = [np.zeros(b.shape) for b in self.bias]\n",
    "        batch_size = len(x[0])\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for w, b in zip(self.weight, self.bias):\n",
    "            z = np.dot(w, x) + b\n",
    "            zs.append(z)\n",
    "            x = sigmoid(z)\n",
    "            activations.append(x)\n",
    "\n",
    "        deltaL = (self.cost).delta(zs[-1], x, y)\n",
    "        gradient_b[-1] = np.sum(deltaL, axis=1, keepdims=True) * 1.0 / batch_size\n",
    "        tmp_gradient_w = np.dot(deltaL, activations[-2].transpose())\n",
    "        gradient_w[-1] = tmp_gradient_w * 1.0 / batch_size\n",
    "\n",
    "        for l in range(2, self.size):\n",
    "            deltaL = np.dot(self.weight[-l+1].transpose(), deltaL) * sigmoid_prime(zs[-l])\n",
    "            gradient_b[-l] = np.sum(deltaL, axis=1, keepdims=True) * 1.0 / batch_size\n",
    "            tmp_gradient_w = np.dot(deltaL, activations[-l-1].transpose())\n",
    "            gradient_w[-l] =  tmp_gradient_w * 1.0 / batch_size\n",
    "\n",
    "        return (gradient_w, gradient_b)\n",
    "\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        result = [(np.argmax(self.feedforward(x)), y)\n",
    "                    for x, y in test_data]\n",
    "        return sum(int(x == y) for x, y in result)\n",
    "\n",
    "net = Network([8, 500, 1], QuadraticCost)\n",
    "net.SGD(training_data, 60, 10, 0.1, lmbda=5.0, test_data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
